<!DOCTYPE html>
<html lang="en-us">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta content="Rust, embedded, development" name="keywords">
<meta content="Jorge Aparicio" name="author">
<meta property="og:title" content="RTFM v2: simpler, less overhead and more device support - Embedded in Rust">
<meta property="og:url" content="http://blog.japaric.io/rtfm-v2/">
<meta property="og:description" content="A blog about Rust and embedded stuff">
<meta property="og:type" content="website" />
<title>RTFM v2: simpler, less overhead and more device support | Embedded in Rust</title>
<link rel="stylesheet" href="http://blog.japaric.io//css/style.css">
<link rel="shortcut icon" href="http://blog.japaric.io//wave.ico">
<link rel="alternate" type="application/atom+xml" title="Embedded in Rust Posts" href="http://blog.japaric.io//index.xml">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/github.min.css">

</head>

<body>
<section class="section">
  <div class="container">
    <nav class="nav">
      <div class="nav-left">
        <a class="nav-item" href="http://blog.japaric.io/"><h1 class="title is-4">Embedded in Rust</h1></a>
      </div>
      <div class="nav-right">
        <nav class="nav-item level is-mobile">
          
          <a class="level-item" href="https://github.com/japaric" target="_blank">
            <span class="icon">
              <i class="fa fa-github"></i>
            </span>
          </a>
          
          <a class="level-item" href="https://twitter.com/japaricious" target="_blank">
            <span class="icon">
              <i class="fa fa-twitter"></i>
            </span>
          </a>
          
          <a class="level-item" href="/index.xml" target="_blank">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>
          </a>
          
        </nav>
      </div>
    </nav>
  </div>
</section>

<section class="section">
  <div class="container">
    <h1 class="title">RTFM v2: simpler, less overhead and more device support</h1>
    <h2 class="subtitle is-5">July 29, 2017 by Jorge Aparicio</h2>
    
      <div class="tags">
    
        <a class="button is-link" href="/tags/arm-cortex-m">ARM Cortex-m</a>
    
        <a class="button is-link" href="/tags/concurrency">concurrency</a>
    
        <a class="button is-link" href="/tags/rtfm">RTFM</a>
    
</div>

    
    <div class="content">
      

<p>Hiya folks! It&rsquo;s been a while. Today I&rsquo;m pleased to present the next version of
the <a href="/fearless-concurrency">Real Time For the Masses</a> framework: <code>cortex-m-rtfm</code> v0.2.0 or just v2,
which is how I like to call it.</p>

<p>Here&rsquo;s the executive summary of the changes:</p>

<ul>
<li><p>v2 is simpler. v1 used a bunch of tokens &ndash; ceiling tokens, priority tokens,
preemption threshold tokens and task tokens &ndash; for memory safety; this made
the API rather boilerplatery. Now most of the tokens as well as the
boilerplate are gone. Porting applications from v1 to v2 should see a
reduction of about 10 to 30% in lines of code.</p></li>

<li><p>v2 has even less overhead. A long standing <a href="/rtfm-overhead/#a-nonzero-cost-pattern">issue</a> with the borrow checker
that required   using <code>Cell</code> or <code>RefCell</code> as a workaround has been fixed.
Making the <code>Resource</code> abstraction truly zero cost.</p></li>

<li><p>v2 fully supports Cortex-M0(+) devices. Now all the Cortex-M devices have the
same level of support in <code>cortex-m-rtfm</code>. Not only that but there&rsquo;s also a
<a href="https://github.com/japaric/msp430-rtfm">port</a> of this version of RTFM for the MSP430 architecture &ndash; with the exact
same API.</p></li>
</ul>

<h1 id="the-new-api">The new API</h1>

<p>Let&rsquo;s dig into the new API by porting some of applications I showed to you in
the <a href="/fearless-concurrency/#hello-world-again">introduction post</a> of RTFM.</p>

<p>All the examples shown here target the <a href="http://wiki.stm32duino.com/index.php?title=Blue_Pill">&ldquo;Blue Pill&rdquo;</a> development board.</p>

<h2 id="hello-world">Hello world</h2>

<p>This is the simplest RTFM application: it has no tasks.</p>

<pre><code class="language-rust">#![feature(proc_macro)] // &lt;- IMPORTANT! Feature gate for procedural macros
#![no_std]

// git = &quot;https://github.com/japaric/blue-pill&quot;, rev = &quot;2b7d5c56b25f4efad6c7c40042f884cbecb47c0b&quot;
extern crate blue_pill;

// version = &quot;0.2.0&quot;
extern crate cortex_m_rtfm as rtfm; // &lt;- this rename is required

// version = &quot;0.2.0&quot;
extern crate cortex_m_semihosting as semihosting;

use core::fmt::Write;

use rtfm::app; // &lt;- this is a procedural macro
use semihosting::hio;

// This macro expands into the `main` function
app! {
    // this is a path to a _device_ crate, a crate generated using svd2rust
    device: blue_pill::stm32f103xx,
}

// INITIALIZATION
fn init(_p: init::Peripherals) {
    // Nothing to initialize in this example ...
}

// IDLE LOOP
fn idle() -&gt; ! {
    writeln!(hio::hstdout().unwrap(), &quot;Hello, world!&quot;).unwrap();

    // Go to sleep
    loop {
        rtfm::wfi();
    }
}
</code></pre>

<p>The most notable change is that the <a href="https://docs.rs/cortex-m-rtfm/0.1.1/cortex_m_rtfm/macro.tasks.html"><code>tasks!</code></a> macro is gone and has been
replaced with a procedural macro: <a href="https://docs.rs/cortex-m-rtfm-macros/0.2.0/cortex_m_rtfm_macros/fn.app.html"><code>app!</code></a>. Procedural macros are the next
iteration of the Rust macro / plugin system and are not yet stable so a feature
gate is required. Don&rsquo;t forget to include it! Or you&rsquo;ll get some rather obscure
errors. Procedural macros are imported into scope using the normal <code>use</code>
mechanism, as if they were functions.</p>

<p>Like the old <code>tasks!</code> macro the <code>app!</code> macro expects a path to the device crate
as an argument. However, the <code>app!</code> macro uses this <code>key: value</code> syntax so the
path must be supplied as the value of the <code>device</code> key.</p>

<p><code>app!</code> will expand into a <code>main</code> function that will call <code>init</code> and then <code>idle</code>,
as it did in the previous version. If you didn&rsquo;t know, you can see what macros
expand to using the <a href="https://crates.io/crates/cargo-expand">cargo-expand</a> subcommand. Here&rsquo;s the expansion of the
<code>app!</code> macro used in the previous program:</p>

<pre><code class="language-console">$ xargo expand
</code></pre>

<pre><code class="language-rust">// ..

mod init {
    pub use blue_pill::stm32f103xx::Peripherals;
}

fn main() {
    let init: fn(stm32f103xx::Peripherals) = init;

    rtfm::atomic(unsafe { &amp;mut rtfm::Threshold::new(0) }, |_t| unsafe {
        init(stm32f103xx::Peripherals::all());
    });

    let idle: fn() -&gt; ! = idle;

    idle();
}

// ..
</code></pre>

<p>As you can see above the <code>init</code> function runs within a <em>global</em> critical section
and can&rsquo;t be preempted during its execution. For that reason it has <em>full
access</em> to all the peripherals of the device in the form of the
<code>init::Peripherals</code> argument. In the previous version of RTFM you had to
explicitly declare all the peripherals you were going to use in your application
as <em>resources</em>, as a bunch of <code>static</code> variables. None of that boilerplate is
required in this version.</p>

<h2 id="serial-loopback">Serial loopback</h2>

<p>Next let&rsquo;s port the <a href="/fearless-concurrency/#serial-loopback">serial loopback application</a> from v1 to v2. Here&rsquo;s the full
code:</p>

<pre><code class="language-rust">#![feature(proc_macro)]
#![no_std]

extern crate blue_pill;
extern crate cortex_m_rtfm as rtfm;

use blue_pill::Serial;
use blue_pill::prelude::*;
use blue_pill::serial::Event;
use blue_pill::time::Hertz;
use rtfm::{app, Threshold};

const BAUD_RATE: Hertz = Hertz(115_200);

app! {
    device: blue_pill::stm32f103xx,

    tasks: {
        // this &quot;USART1&quot; refers to the interrupt
        USART1: {
            path: loopback,

            // this &quot;USART1&quot; refers to the peripheral
            resources: [USART1],
        },
    },
}

fn init(p: init::Peripherals) {
    let serial = Serial(p.USART1);

    serial.init(BAUD_RATE.invert(), p.AFIO, None, p.GPIOA, p.RCC);

    // RXNE event = a new byte of data has arrived
    serial.listen(Event::Rxne);
}

fn idle() -&gt; ! {
    // Sleep
    loop {
        rtfm::wfi();
    }
}

fn loopback(_t: &amp;mut Threshold, r: USART1::Resources) {
    let serial = Serial(&amp;**r.USART1);

    // grab the byte we just received
    let byte = serial.read().unwrap();

    // and send it back
    serial.write(byte).unwrap();
}
</code></pre>

<p>Here we re-introduce the concept of tasks. A task is effectively a response to
some (external) event in the form of a handler / callback function. In this case
the only event the application will respond to is the arrival of new data
through the serial interface. And the response to that event, the <code>loopback</code>
function, is to send back the received data through the serial interface.</p>

<p>This program initializes the serial interface in <code>init</code> and then goes to sleep
in <code>idle</code>. But whenever a new byte of data arrives through the serial interface
it will temporarily wake up to execute the <code>loopback</code> handler; then it will go
back to sleep. In more detail: the new data <em>event</em> causes the <code>loopback</code> task
to become <em>pending</em>. As the <code>loopback</code> task has higher priority than the <code>idle</code>
loop (all tasks have higher priority than <code>idle</code>) the scheduler will suspend
<code>idle</code> to execute the <code>loopback</code> task &ndash; this is known as preemption. Once the
task is completed <code>idle</code> is resumed; this sends the processor back to sleep.</p>

<p>Code wise tasks are <em>declared</em> in the <code>app!</code> macro. As each task is associated
to an interrupt (interrupts are a hardware mechanism for preemption) they are
declared using the name of the interrupt &ndash; <code>USART1</code> in this case. The task
declaration must include: the <code>path</code> to the task handler and which <code>resources</code>
the task has access to. The resources can be peripherals or plain data (<code>static</code>
variables).</p>

<p>This last part, the <code>resources</code> array, is the most important change since v1. In
v1 resources had global visibility and the user had to assign them a <em>ceiling</em>
to make them safe to share between tasks. This was not optimal: although it was
impossible to pick a ceiling that would break memory safety it was possible to
pick a ceiling that imposed more critical sections, and thus more runtime
overhead, than strictly necessary for memory safety.</p>

<p>In v2 you assign resources to tasks and the optimal ceilings are computed
<em>automatically</em> so the number of critical sections is minimized without user
effort. Memory safety, in v2, is obtained by limiting <em>where</em> the resource is
visible (that is its scope), so resources no longer have global visibility.
Dropping global visibility eliminated the need for most of the tokens needed in
v1.</p>

<p>In this particular program the <code>loopback</code> task needs access to the <code>USART1</code>
peripheral so <code>USART1</code> is declared as its resource. As no other task, or the
idle loop, has access the same resource the <code>loopback</code> task ends up having
<em>exclusive access</em> to the <code>USART1</code> resource, that is a mutable reference
(<code>&amp;mut-</code>) to the peripheral. This mutable reference is packed in the
<code>USART1::Resources</code> argument.</p>

<h2 id="blinky">Blinky</h2>

<p>Now let&rsquo;s port the classic &ldquo;blinky&rdquo; application to v2. The v1 version is <a href="/fearless-concurrency/#a-blinking-task">here</a>.</p>

<pre><code class="language-rust">#![feature(proc_macro)]
#![no_std]

extern crate blue_pill;
extern crate cortex_m;
extern crate cortex_m_rtfm as rtfm;

use blue_pill::led::{self, Green};
use cortex_m::peripheral::SystClkSource;
use rtfm::{app, Threshold};

app! {
    device: blue_pill::stm32f103xx,

    resources: {
        static ON: bool = false;
    },

    tasks: {
        SYS_TICK: {
            path: toggle,
            resources: [ON],
        },
    },
}

fn init(p: init::Peripherals, _r: init::Resources) {
    led::init(p.GPIOC, p.RCC);

    // Configure the system timer to generate periodic events at 1 Hz rate
    p.SYST.set_clock_source(SystClkSource::Core);
    p.SYST.set_reload(8_000_000); // Period = 1s
    p.SYST.enable_interrupt();
    p.SYST.enable_counter();
}

fn idle() -&gt; ! {
    // Sleep
    loop {
        rtfm::wfi();
    }
}

// TASKS

// Toggle the state of the LED
fn toggle(_t: &amp;mut Threshold, r: SYS_TICK::Resources) {
    **r.ON = !**r.ON;

    if **r.ON {
        Green.on();
    } else {
        Green.off();
    }
}
</code></pre>

<p>Again we have a single task and that task has only one resource. However, this
time the resource is not a peripheral but plain data. The <code>ON</code> variable tracks
whether the LED is on or off.</p>

<p>Data resources must be declared and initialized in the <code>resources</code> key of the
<code>app!</code> macro. Declaration of data resources looks exactly like the declaration
of <code>static</code> variables.</p>

<p>Like in the previous program the <code>toggle</code> task is the only &ldquo;owner&rdquo; of the <code>ON</code>
resource so it has exclusive access (<code>&amp;mut-</code>) to it.</p>

<p>If you were wondering &ldquo;what&rsquo;s up with the double dereference (<code>**</code>) in the
<code>toggle</code> function?&rdquo; that&rsquo;s required becaused the type of <code>r.ON</code> is <code>&amp;mut
Static&lt;bool&gt;</code> instead of <code>&amp;mut bool</code>; both are semantically equal because
<code>Static</code> is just a newtype. The <code>Static</code> newtype comes in handy when dealing
with DMA based APIs and code that deals with resources in a generic fashion.</p>

<p>One extra thing to note here is that we are using the <code>SYS_TICK</code> exception,
which is available to all Cortex-M microcontrollers, as a task instead of a
device specific interrupt like <code>TIM2</code>. This is something new in v2; v1 didn&rsquo;t
support these Cortex-M exceptions.</p>

<p>If you are a careful observer then you probably noticed that the signature of
the <code>init</code> function changed in this program: it now includes a <code>init::Resources</code>
argument. This argument is a collection of all the data resources declared in
<code>app!</code>. Basically the <code>init</code> function has exclusive access (<code>&amp;mut-</code>) to all the
data resources; this can be used to initialize resources at runtime.</p>

<h2 id="concurrency">Concurrency</h2>

<p>In the next example we&rsquo;ll merge the previous loopback and blinky programs into
one. The resulting program will run the two tasks <em>concurrently</em>. As there&rsquo;s no
data sharing because each task uses different resources merging the two programs
is straightforward. Here&rsquo;s the full code:</p>

<pre><code class="language-rust">#![feature(proc_macro)]
#![no_std]

extern crate blue_pill;
extern crate cortex_m;
extern crate cortex_m_rtfm as rtfm;

use blue_pill::Serial;
use blue_pill::led::{self, Green};
use blue_pill::prelude::*;
use blue_pill::serial::Event;
use blue_pill::time::Hertz;
use cortex_m::peripheral::SystClkSource;
use rtfm::{app, Threshold};

const BAUD_RATE: Hertz = Hertz(115_200);

app! {
    device: blue_pill::stm32f103xx,

    resources: {
        static ON: bool = false;
    },

    // There are now two tasks!
    tasks: {
        SYS_TICK: {
            path: toggle,
            resources: [ON],
        },

        USART1: {
            path: loopback,
            resources: [USART1],
        },
    },
}

// The new `init` is the fusion of the other two programs' `init` functions
fn init(p: init::Peripherals, _r: init::Resources) {
    let serial = Serial(p.USART1);

    led::init(p.GPIOC, p.RCC);

    serial.init(BAUD_RATE.invert(), p.AFIO, None, p.GPIOA, p.RCC);
    serial.listen(Event::Rxne);

    p.SYST.set_clock_source(SystClkSource::Core);
    p.SYST.set_reload(8_000_000); // 1s
    p.SYST.enable_interrupt();
    p.SYST.enable_counter();
}

fn idle() -&gt; ! {
    loop {
        rtfm::wfi();
    }
}

// TASKS

// Task code is unchanged
fn loopback(_t: &amp;mut Threshold, r: USART1::Resources) {
    let serial = Serial(&amp;**r.USART1);

    let byte = serial.read().unwrap();
    serial.write(byte).unwrap();
}

// Task code is unchanged
fn toggle(_t: &amp;mut Threshold, r: SYS_TICK::Resources) {
    **r.ON = !**r.ON;

    if **r.ON {
        Green.on();
    } else {
        Green.off();
    }
}
</code></pre>

<h2 id="sharing-data">Sharing data</h2>

<p>Now let&rsquo;s see what happens if both tasks need to modify the same resource. Let&rsquo;s
say we want to count the number of context switches, which is the number of
times the processor wakes up to run a task, for performance tracking purposes.
For simplicity, we&rsquo;ll omit the part that logs the performance metrics. The
required changes are shown below:</p>

<pre><code class="language-rust">app! {
    device: blue_pill::stm32f103xx,

    resources: {
        static CONTEXT_SWITCHES: u32 = 0; // &lt;- NEW!
        static ON: bool = false;
    },

    tasks: {
        SYS_TICK: {
            path: toggle,
            resources: [CONTEXT_SWITCHES, ON], // &lt;- NEW!
        },

        USART1: {
            path: loopback,
            resources: [CONTEXT_SWITCHES, USART1], // &lt;- NEW!
        },
    },
}

// TASKS
fn loopback(r: USART1::Resources) {
    **r.CONTEXT_SWITCHES += 1; // &lt;- NEW!

    // .. same code as before ..
}

fn toggle(r: SYS_TICK::Resources) {
    **r.CONTEXT_SWITCHES += 1; // &lt;- NEW!

    // .. same code as before ..

    // .. some code that logs `CONTEXT_SWITCHES` and resets its value to 0 ..
}
</code></pre>

<p>Another straightforward change but only because both tasks are operating at the
<em>same</em> priority so one task can only start if the other one is not running. This
means that no data race is possible so each task has exclusive access (<code>&amp;mut-</code>)
to the <code>CONTEXT_SWITCHES</code> resource <em>in turns</em>.</p>

<h2 id="preemption">Preemption</h2>

<p>RTFM supports prioritization of tasks. As I mentioned before when a higher
priority task becomes pending the scheduler suspends the current task to run the
higher priority task to completion. If not specified in the <code>app!</code> macro all
tasks default to a priority of 1, which is the lowest priority a task can have.
<code>idle</code>, on the other hand, has a priority of 0.</p>

<p>Let&rsquo;s suppose we now want to increase the priority of the <code>loopback</code> task
because the incoming data throughput has increased and waiting for the <code>toggle</code>
task to end before we can service <code>loopback</code> may cause data loss.</p>

<p>If we go ahead and simply increase the priority of the <code>loopback</code> to 2 in the
previous program it will no longer compile:</p>

<pre><code class="language-rust">app! {
    device: blue_pill::stm32f103xx,

    resources: {
        static CONTEXT_SWITCHES: u32 = 0;
        static ON: bool = false;
    },

    tasks: {
        SYS_TICK: {
            path: toggle,
            priority: 1, // &lt;- this can be omitted, but let's be explicit for clarity
            resources: [CONTEXT_SWITCHES, ON],
        },

        USART1: {
            path: loopback,
            priority: 2, // &lt;- priority increased
            resources: [CONTEXT_SWITCHES, USART1],
        },
    },
}

// ..
</code></pre>

<pre><code class="language-console">$ xargo build
error[E0614]: type `_resource::CONTEXT_SWITCHES` cannot be dereferenced
  --&gt; examples/sharing.rs:75:6
   |
75 |     **r.CONTEXT_SWITCHES += 1;
   |      ^^^^^^^^^^^^^^^^^^^

error: aborting due to previous error
</code></pre>

<p>The code around line 75 is this one:</p>

<pre><code class="language-rust">fn toggle(r: SYS_TICK::Resources) {
    **r.CONTEXT_SWITCHES += 1;

    // .. same code as before ..
}
</code></pre>

<p>So the <code>toggle</code> task can no longer <em>directly</em> access the <code>CONTEXT_SWITCHES</code>
resource data. Good! This compile error just prevented a data race: with the
priority change <code>loopback</code> can now preempt the <code>toggle</code> task; since
incrementing <code>CONTEXT_SWITCHES</code> is <em>not</em> performed in a single instruction but
as a Read Modify Write (RMW) operation the two RMW operations, the one in
<code>loopback</code> and one in <code>toggle</code>, can now race and that can result in data loss as
shown below:</p>

<pre><code class="language-console">start:    CONTEXT_SWITCHES == 1

toggle:   let mut register = CONTEXT_SWITCHES.read(); // register = 1
toggle:   register += 1;                              // register = 2

~ interrupt start ~

loopback: let mut register = CONTEXT_SWITCHES.read(); // register = 1
loopback: register += 1;                              // register = 2
loopback: CONTEXT_SWITCHES.store(register);           // CONTEXT_SWITCHES = 2
..

~ interrupt end ~

toggle:   CONTEXT_SWITCHES.store(register);           // CONTEXT_SWITCHES = 2
..

end:      CONTEXT_SWITCHES == 2                       // should have been 3!
</code></pre>

<p>Which doesn&rsquo;t seem <em>too</em> bad, but if either task was performing a more complex
operation on <code>CONTEXT_SWITCHES</code> this data race could have resulted in Undefined
Behavior (UB) due to compiler misoptimizations.</p>

<p>To eliminate this data race we have to use critical section: enter <a href="https://docs.rs/cortex-m-rtfm/0.2.1/cortex_m_rtfm/trait.Resource.html"><code>claim</code> and
<code>claim_mut</code></a>.</p>

<pre><code class="language-rust">fn toggle(t: &amp;mut Threshold, mut r: SYS_TICK::Resources) {
    use rtfm::Resource; // &lt;- trait that provides the `claim{,_mut}` method

    r.CONTEXT_SWITCHES.claim_mut(t, |context_switches, _t| {
        // Inside a critical section
        **context_switches += 1;
    });

    // ..
}
</code></pre>

<p><code>claim_mut</code> creates a critical section and only within this critical section can
the resource data be read and modified. This critical section makes the RMW
operation on <code>CONTEXT_SWITCHES</code> uninterruptible by the <code>loopback</code> task. Now the
concurrent RMW operations can&rsquo;t overlap and the possibility of data races has
been eliminated.</p>

<p>That&rsquo;s pretty much it for the core of the new API. As usual you can check out
the API documentation on <a href="https://docs.rs/cortex-m-rtfm/0.2.1/cortex_m_rtfm/">docs.rs</a>.</p>

<h1 id="critical-sections-and-threshold">Critical sections and <code>Threshold</code></h1>

<p>I think this is good time to tell you, or remind you, that RTFM has <em>two</em>
flavors of critical sections: global ones and non-global ones. The non-global
ones are the ones you get when you use <code>claim</code> and <code>claim_mut</code>; these critical
sections prevent <em>some</em> tasks from preempting the current one whereas <em>global</em>
critical sections prevent <em>all</em> tasks from starting.</p>

<p>As a rule of thumb you should only use non global critical sections unless you
really need a global critical section. Non global critical sections impose less
task blocking so are they better from a real time scheduling point of view.</p>

<p>Here&rsquo;s a contrived example that showcases the two types of critical sections:</p>

<pre><code class="language-rust">#![feature(proc_macro)]
#![no_std]

extern crate blue_pill;
extern crate cortex_m;
extern crate cortex_m_rtfm as rtfm;

use blue_pill::stm32f103xx::Interrupt;
use rtfm::{app, Resource, Threshold};

app! {
    device: blue_pill::stm32f103xx,

    resources: {
        static R1: bool = false;
    },

    tasks: {
        EXTI0: {
            path: exti0,
            priority: 1,
            resources: [R1],
        },

        EXTI1: {
            path: exti1,
            priority: 2,
            resources: [R1],
        },

        EXTI2: {
            path: exti2,
            priority: 3,
        },
    },
}

fn init(_p: init::Peripherals, _r: init::Resources) {}

fn idle() -&gt; ! {
    loop {
        rtfm::wfi();
    }
}

fn exti0(t: &amp;mut Threshold, r: EXTI0::Resources) {
    // Threshold == 1

    rtfm::set_pending(Interrupt::EXTI1); // ~&gt; exti1

    // non-global critical section
    r.R1.claim(t, |_r1, _t| {
        // Threshold = 2
        rtfm::set_pending(Interrupt::EXTI1);

        rtfm::set_pending(Interrupt::EXTI2); // ~&gt; exti2
    }); // Threshold = 1

    // ~&gt; exti1

    // global critical section
    rtfm::atomic(t, |t| {
        // Threshold = MAX
        let _r1 = r.R1.borrow(t);

        rtfm::set_pending(Interrupt::EXTI1);

        rtfm::set_pending(Interrupt::EXTI2);
    }); // Threshold = 1

    // ~&gt; exti2, exti1
}

fn exti1(_r: EXTI1::Resources) {
    // .. modify R1 ..
}

fn exti2() {
    // ..
}
</code></pre>

<p>In <code>exti0</code> the data of R1 is accessed using a non global critical section and
then again using a global critical section. Both critical sections contain
pretty much the same code but behave differently. Let&rsquo;s see why:</p>

<p>But first let&rsquo;s define what <code>Threshold</code> is &ndash; I have been ignoring it for a
while now. <code>Threshold</code> is a <em>token</em> that keeps track of the current <em>preemption
threshold</em>. This threshold indicates what priority a task must have to be able
to preempt the current task. A threshold of 1 means that a task must have <em>at
least</em> a priority of 2 to preempt the current task.</p>

<p>Now let&rsquo;s go back to the program analysis:</p>

<p>Because the priority of <code>exti0</code> is 1 the preemption threshold, tracked by the
token <code>t</code>, starts at a value of 1. At the start of <code>exti0</code> we set the task
<code>EXTI1</code> as <a href="https://docs.rs/cortex-m-rtfm/0.2.1/cortex_m_rtfm/fn.set_pending.html">pending</a>. Because <code>EXTI1</code> has a priority of 2, which is greater than
the current preemption threshold of 1, it will be executed immediately.</p>

<p>Then we <code>claim</code> the resource <code>R1</code>; this creates a critical section by increasing
the preemption threshold, now tracked by <code>_t</code>, to 2. Within this critical
section the data of the resource <code>R1</code> can be read through the <code>_r1</code> reference.
Then, within the critical section, we set the task <code>EXTI1</code> as pending; however,
the task won&rsquo;t be executed immediately because its priority, 2, is equal to the
current preemption threshold of 2. Then we set the task <code>EXTI2</code> as pending; this
time the task will be serviced immediately because its priority, 3, is higher
than the current threshold of 2.</p>

<p>Once the <code>claim</code> ends the threshold is restored to its previous value of 1. Now
the task <code>EXTI1</code> can again preempt the current task so it gets executed.</p>

<p>Then we have <code>rtfm::atomic</code>, a <em>global</em> critical section. Within this critical
section we can access the data of the resource <code>R1</code> using the <a href="https://docs.rs/cortex-m-rtfm/0.2.1/cortex_m_rtfm/trait.Resource.html#tymethod.borrow"><code>borrow</code></a> method.
A global critical section effectively raises the preemption threshold to its
maximum possible value so <em>no task</em> can preempt it. Within this critical section
we set the tasks <code>EXTI1</code> and <code>EXTI2</code> as pending, but none of them can run
because of the threshold value.</p>

<p>Once <code>rtfm::atomic</code> ends the preemption threshold is restored to its previous
value of 1. Now the tasks can be serviced: <code>EXTI2</code> is serviced first, because of
its higher priority, then <code>EXTI1</code> is serviced.</p>

<h1 id="performance">Performance</h1>

<p>I wrote a <a href="/rtfm-overhead">blog post</a> where I analyzed the runtime cost of the primitives provided
by RTFM v1. Those numbers mostly hold for v2 with the difference that <code>claim</code>
and <code>claim_mut</code> are equivalent to v1&rsquo;s <code>Threshold.raise</code> but only when the
threshold <em>needs</em> to be raised; when the threshold doesn&rsquo;t need to be raised
<code>claim</code> and <code>claim_mut</code> are no-ops. To elaborate with an example:</p>

<p>This single claim</p>

<pre><code class="language-rust">app! {
    // ..

    tasks: {
        EXTI0: {
            path: exti0,
            priority: 1,
            resources: [R1],
        },

        EXTI1: {
            path: exti1,
            priority: 2,
            resources: [R1],
        },
    },
}

fn exti0(t: &amp;mut Threshold, r: EXTI0::Resources) {
    r.R1.claim(t, |_r1, _t| {
        asm::nop();
    });
}
</code></pre>

<p>produces this machine code</p>

<pre><code class="language-armasm">08000196 &lt;EXTI0&gt;:
 8000196:       f3ef 8011       mrs     r0, BASEPRI
 800019a:       21e0            movs    r1, #224        ; 0xe0
 800019c:       f381 8812       msr     BASEPRI, r1     ; enter
 80001a0:       bf00            nop
 80001a2:       f380 8811       msr     BASEPRI, r0     ; exit
 80001a6:       4770            bx      lr
</code></pre>

<p>Whereas this nested claim</p>

<pre><code class="language-rust">app! {
    // ..

    tasks: {
        EXTI0: {
            path: exti0,
            priority: 1,
            resources: [R1, R2],
        },

        EXTI1: {
            path: exti1,
            priority: 2,
            resources: [R1, R2],
        },
    },
}

fn exti0(t: &amp;mut Threshold, r: EXTI0::Resources) {
    r.R1.claim(t, |_r1, t| {
        asm::nop();

        r.R2.claim(t, |_r2, _t| {
            asm::nop();
        });

        asm::nop();
    });
}
</code></pre>

<p>produces this machine code</p>

<pre><code class="language-armasm">08000196 &lt;EXTI0&gt;:
 8000196:       f3ef 8011       mrs     r0, BASEPRI
 800019a:       21e0            movs    r1, #224        ; 0xe0
 800019c:       f381 8812       msr     BASEPRI, r1     ; enter
 80001a0:       bf00            nop
 80001a2:       bf00            nop
 80001a4:       bf00            nop
 80001a6:       f380 8811       msr     BASEPRI, r0     ; exit
 80001aa:       4770            bx      lr
</code></pre>

<p>The inner claim is a no-op here because the threshold doesn&rsquo;t need to be raised
again to achieve memory safety.</p>

<p>On the other hand, this similarly looking nested claim</p>

<pre><code>app! {
    // ..

    tasks: {
        EXTI0: {
            path: exti0,
            priority: 1,
            resources: [R1, R2],
        },

        EXTI1: {
            path: exti1,
            priority: 2,
            resources: [R1],
        },

        EXTI2: {
            path: exti2,
            priority: 3,
            resources: [R2],
        },
    },
}

fn exti0(t: &amp;mut Threshold, r: EXTI0::Resources) {
    r.R1.claim(t, |_r1, t| {
        asm::nop();

        r.R2.claim(t, |_r2, _t| {
            asm::nop();
        });

        asm::nop();
    });
}
</code></pre>

<p>does result in two nested critical sections</p>

<pre><code class="language-armasm">08000196 &lt;EXTI0&gt;:
 8000196:       21e0            movs    r1, #224        ; 0xe0
 8000198:       f3ef 8011       mrs     r0, BASEPRI
 800019c:       22d0            movs    r2, #208        ; 0xd0
 800019e:       f381 8812       msr     BASEPRI, r1     ; enter outer
 80001a2:       bf00            nop
 80001a4:       f3ef 8111       mrs     r1, BASEPRI
 80001a8:       f382 8812       msr     BASEPRI, r2     ; enter inner
 80001ac:       bf00            nop
 80001ae:       f381 8811       msr     BASEPRI, r1     ; exit inner
 80001b2:       bf00            nop
 80001b4:       f380 8811       msr     BASEPRI, r0     ; exit outer
 80001b8:       4770            bx      lr
</code></pre>

<p>because they are required for memory safety in this case.</p>

<h2 id="rtfm-atomic"><code>rtfm::atomic</code></h2>

<p>The overhead of <code>rtfm::atomic</code> has also been reduced. This critical section
works by temporarily disabling interrupts. In v1, <code>rtfm::atomic</code> checked at
runtime (by reading the <code>PRIMASK</code> register) if interrupts were disabled before
executing the closure to prevent enabling the interrupts after executing the
closure. This check is not necessary in v2 because the signature of
<code>rtfm::atomic</code> has changed to take the <code>Threshold</code> token, which contains
information about the state of interrupts, so whether the interrupts are enabled
or not is now known at compile time.</p>

<p>This code</p>

<pre><code class="language-rust">fn exti0(t: &amp;mut Threshold, r: EXTI0::Resources) {
    rtfm::bkpt();

    rtfm::atomic(t, |_t| {});

    rtfm::bkpt();
}
</code></pre>

<p>now produces this machine code</p>

<pre><code class="language-armasm">08000198 &lt;EXTI0&gt;:
 8000198:       be00            bkpt    0x0000
 800019a:       b672            cpsid   i
 800019c:       b662            cpsie   i
 800019e:       be00            bkpt    0x0000
 80001a0:       4770            bx      lr
</code></pre>

<p>The runtime overhead of v2&rsquo;s <code>rtfm::atomic</code> is 3 cycles, down from <a href="/rtfm-overhead/#vs-rtfm-atomic">the 6 cycles
of v1</a>.</p>

<p>If nested the inner <code>rtfm::atomic</code> become a no-op. For example, this</p>

<pre><code class="language-rust">fn exti0(t: &amp;mut Threshold, r: EXTI0::Resources) {
    rtfm::atomic(t, |t| {
        asm::nop();

        rtfm::atomic(t, |_t| {
            asm::nop();
        });

        asm::nop();
    });
}
</code></pre>

<p>produces this:</p>

<pre><code class="language-armasm">08000196 &lt;EXTI0&gt;:
 8000196:       b672            cpsid   i
 8000198:       bf00            nop
 800019a:       bf00            nop
 800019c:       bf00            nop
 800019e:       b662            cpsie   i
 80001a0:       4770            bx      lr
</code></pre>

<h2 id="zero-cost-mutation">Zero cost mutation</h2>

<p>The area where v2 does much better than v1, in terms of performance, is mutation
of non primitive types. In v1 you could only get a shared reference (<code>&amp;-</code>), to
the resource data. This meant that you had to use a <code>Cell</code> or a <code>RefCell</code> to
mutate the data; these two abstractions have overhead compared to a plain
mutable reference (<code>&amp;mut-</code>). In v2 you can get a mutable reference to the data
with no extra overhead.</p>

<p>Here&rsquo;s some <a href="/rtfm-overhead/#access-mut">code that didn&rsquo;t compile in v1</a> (without the help of <code>Cell</code> /
<code>RefCell</code>).</p>

<pre><code class="language-rust">app! {
    device: blue_pill::stm32f103xx,

    resources: {
        static A: i32 = 0;
        static B: i32 = 0;
    },

    tasks: {
        EXTI0: {
            path: exti0,
            priority: 1,
            resources: [A, B],
        },

        EXTI1: {
            path: exti1,
            priority: 2,
            resources: [A, B],
        },
    },
}

// higher priority task
fn exti1(t: &amp;mut Threshold, r: EXTI1::Resources) {
    **r.A += 1;
    **r.B += 2;

    mem::swap(r.A, r.B);
}

// lower priority task
fn exti0(
    t: &amp;mut Threshold,
    EXTI0::Resources { mut A, mut B }: EXTI0::Resources,
) {
    A.claim_mut(t, |a, _| **a += 1);
    B.claim_mut(t, |b, _| **b += 2);

    A.claim_mut(t, |a, t| {
        B.claim_mut(t, |b, _| {
            mem::swap(a, b);
        });
    });
}
</code></pre>

<p>The above code produces this machine code:</p>

<pre><code class="language-armasm">08000196 &lt;EXTI1&gt;:
 8000196:       f240 0000       movw    r0, #0
 800019a:       f2c2 0000       movt    r0, #8192       ; 0x2000
 800019e:       e9d0 1200       ldrd    r1, r2, [r0]
 80001a2:       3202            adds    r2, #2
 80001a4:       3101            adds    r1, #1
 80001a6:       e9c0 2100       strd    r2, r1, [r0]
 80001aa:       4770            bx      lr

080001ac &lt;EXTI0&gt;:
 80001ac:       f240 0200       movw    r2, #0
 80001b0:       21e0            movs    r1, #224        ; 0xe0
 80001b2:       f3ef 8011       mrs     r0, BASEPRI
 80001b6:       f381 8811       msr     BASEPRI, r1     ; enter I
 80001ba:       f2c2 0200       movt    r2, #8192       ; 0x2000
 80001be:       6813            ldr     r3, [r2, #0]
 80001c0:       3301            adds    r3, #1
 80001c2:       6013            str     r3, [r2, #0]
 80001c4:       f380 8811       msr     BASEPRI, r0     ; leave I
 80001c8:       f3ef 8011       mrs     r0, BASEPRI
 80001cc:       f381 8811       msr     BASEPRI, r1     ; enter II
 80001d0:       6853            ldr     r3, [r2, #4]
 80001d2:       3302            adds    r3, #2
 80001d4:       6053            str     r3, [r2, #4]
 80001d6:       f380 8811       msr     BASEPRI, r0     ; leave II
 80001da:       f3ef 8011       mrs     r0, BASEPRI
 80001de:       f381 8811       msr     BASEPRI, r1     ; enter III
 80001e2:       e9d2 1300       ldrd    r1, r3, [r2]
 80001e6:       e9c2 3100       strd    r3, r1, [r2]
 80001ea:       f380 8811       msr     BASEPRI, r0     ; leave III
 80001ee:       4770            bx      lr
</code></pre>

<h1 id="outro">Outro</h1>

<p>That&rsquo;s it for this post. I hope that you agree with me that the new system is
simpler. Please give it a try and let me know what you think! If you need more
convincing here are some open source applications that are using RTFM v2:</p>

<ul>
<li><p>Cortex-M</p>

<ul>
<li><a href="https://github.com/japaric/2wd"><code>2wd</code></a>, a remotely controlled wheeled robot</li>
<li><a href="https://github.com/japaric/blue-pill"><code>blue-pill</code></a>, bunch of example apps for the Blue Pill development board</li>
<li><a href="https://github.com/japaric/ws2812b"><code>ws2812b</code></a>, WS2812B LED ring controlled via a serial interface</li>
</ul></li>

<li><p>MSP430</p>

<ul>
<li><a href="https://github.com/cr1901/AT2XT/"><code>AT2XT</code></a>, AT to XT Keyboard Protocol Converter</li>
</ul></li>
</ul>

<p>And of course there are always <a href="https://github.com/japaric/cortex-m-rtfm/milestone/1">new features</a> in the pipeline.</p>

<hr />

<p><strong>Thank you patrons! ❤️</strong></p>

<p>I want to wholeheartedly thank:</p>

<p style="text-align:center">
  <a href="http://www.sharebrained.com/" style="border-bottom:0px">
    <img alt="ShareBrained Technology" src="/logo/sharebrained.png" width="200"/>
  </a>
</p>

<p><a href="https://github.com/Razican">Iban Eguia</a>, <a href="https://github.com/aturon">Aaron Turon</a>, <a href="https://github.com/archaelus">Geoff Cant</a>, <a href="http://www.harrisonchin.com/">Harrison Chin</a>, <a href="https://github.com/brandonedens">Brandon Edens</a>,
<a href="https://github.com/whitequark">whitequark</a>, <a href="https://convolv.es/">J. Ryan Stinnett</a>, <a href="https://jamesmunns.com/">James Munns</a> and 27 more people
for <a href="https://goo.gl/DZtACV">supporting my work on Patreon</a>.</p>

<hr />

<p>Let&rsquo;s discuss on <a href="https://www.reddit.com/r/rust/comments/6q9s76/rtfm_v2_simpler_less_overhead_and_more_device/">reddit</a>.</p>

<p>Enjoyed this post? Like my work on embedded stuff? Consider supporting my work
on <a href="https://goo.gl/DZtACV">Patreon</a>!</p>

<p>Follow me on <a href="https://twitter.com/japaricious">twitter</a> for even more embedded stuff.</p>

<p>The embedded Rust community gathers on the #rust-embedded IRC channel
(irc.mozilla.org). Join us!</p>

    </div>

    
    
    <div class="article-toc" >
        <h3>Contents</h3>
        <nav id="TableOfContents">
<ul>
<li><a href="#the-new-api">The new API</a>
<ul>
<li><a href="#hello-world">Hello world</a></li>
<li><a href="#serial-loopback">Serial loopback</a></li>
<li><a href="#blinky">Blinky</a></li>
<li><a href="#concurrency">Concurrency</a></li>
<li><a href="#sharing-data">Sharing data</a></li>
<li><a href="#preemption">Preemption</a></li>
</ul></li>
<li><a href="#critical-sections-and-threshold">Critical sections and <code>Threshold</code></a></li>
<li><a href="#performance">Performance</a>
<ul>
<li><a href="#rtfm-atomic"><code>rtfm::atomic</code></a></li>
<li><a href="#zero-cost-mutation">Zero cost mutation</a></li>
</ul></li>
<li><a href="#outro">Outro</a></li>
</ul>
</nav>
    </div>
    
    

    
  </div>
</section>


<section class="section">
  <div class="container has-text-centered">
    <p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by/4.0/80x15.png" /></a><br/>Jorge Aparicio</p>
  </div>
</section>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/tomorrow-night.min.css" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js" integrity="sha256-+bhVTaRmJ/c07eV80nU8gD2cBBF0rYkf1txqXlrbvb0=" crossorigin="anonymous"></script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/languages/armasm.min.js"></script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/languages/rust.min.js"></script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/languages/shell.min.js"></script>

<script>hljs.initHighlightingOnLoad();</script>


<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-87779174-3', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>



</body>
